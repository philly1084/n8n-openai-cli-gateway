providers:
  - id: gemini-cli
    type: cli
    description: Gemini via OpenCode + Google OAuth plugin
    models:
      - id: gemini-2.5-pro
        providerModel: google/gemini-2.5-pro
        fallbackModels:
          - gpt-4.1
      - id: gemini-2.5-flash
        providerModel: google/gemini-2.5-flash
        fallbackModels:
          - gpt-4.1
    responseCommand:
      executable: opencode
      args:
        - run
        - --model
        - "{{provider_model}}"
        - --format
        - default
        - "{{prompt}}"
      input: prompt_stdin
      output: text
      timeoutMs: 240000
    auth:
      loginCommand:
        executable: opencode
        args:
          - auth
          - login
        timeoutMs: 900000
      statusCommand:
        executable: sh
        args:
          - -c
          - opencode auth list | grep -qi google
        timeoutMs: 30000
      # Example: Rate limit check command
      # This should output JSON with rate limit information
      # rateLimitCommand:
      #   executable: opencode
      #   args:
      #     - account
      #     - limits
      #     - --json
      #   timeoutMs: 30000

  - id: antigravity-cli
    type: cli
    description: Antigravity CLI adapter
    models:
      - id: antigravity-default
        providerModel: default
    responseCommand:
      executable: antigravity
      args:
        - chat
        - --model
        - "{{provider_model}}"
        - --json
      input: request_json_stdin
      output: json_contract
      timeoutMs: 240000
    auth:
      loginCommand:
        executable: antigravity
        args:
          - auth
          - login
          - --no-browser
        timeoutMs: 900000
      statusCommand:
        executable: antigravity
        args:
          - auth
          - status
          - --json
        timeoutMs: 30000

  - id: codex-cli
    type: cli
    description: OpenAI Codex app-server bridge adapter
    models:
      - id: codex-latest
        providerModel: codex-latest
        fallbackModels:
          - gemini-2.5-pro
      - id: gpt-4.1
        providerModel: gpt-4.1
        fallbackModels:
          - gemini-2.5-flash
    responseCommand:
      executable: node
      args:
        - dist/scripts/codex-appserver-bridge.js
        - --model
        - "{{provider_model}}"
      input: request_json_stdin
      output: json_contract
      timeoutMs: 240000
    auth:
      loginCommand:
        executable: codex
        args:
          - login
          - --no-browser
        timeoutMs: 900000
      statusCommand:
        executable: codex
        args:
          - whoami
          - --json
        timeoutMs: 30000
      # Example: OpenAI rate limit check
      # This would call the OpenAI API to check usage/limits
      # rateLimitCommand:
      #   executable: sh
      #   args:
      #     - -c
      #     - |
      #       curl -s https://api.openai.com/v1/dashboard/billing/credit_grants \
      #         -H "Authorization: Bearer $OPENAI_API_KEY" \
      #         -H "Content-Type: application/json" | \
      #         jq '{limitType: "credits", remaining: .total_available, maxAllowed: .total_granted}'
      #   timeoutMs: 30000

  # ============================================================================
  # FREE AI SERVICES
  # ============================================================================

  - id: ollama-local
    type: cli
    description: Local LLMs via Ollama (completely free, runs locally)
    models:
      - id: llama3.2
        providerModel: llama3.2
        fallbackModels:
          - mistral
      - id: mistral
        providerModel: mistral
        fallbackModels:
          - codellama
      - id: codellama
        providerModel: codellama
        fallbackModels:
          - llama3.2
      - id: phi4
        providerModel: phi4
      - id: qwen2.5
        providerModel: qwen2.5
    responseCommand:
      executable: ollama
      args:
        - run
        - "{{provider_model}}"
      input: prompt_stdin
      output: text_plain
      timeoutMs: 300000
    # No auth needed for local Ollama

  - id: groq-api
    type: cli
    description: Groq API - very fast inference with generous free tier
    models:
      - id: llama-3.3-70b
        providerModel: llama-3.3-70b-versatile
        fallbackModels:
          - mixtral-8x7b
      - id: mixtral-8x7b
        providerModel: mixtral-8x7b-32768
        fallbackModels:
          - gemma2-9b
      - id: gemma2-9b
        providerModel: gemma2-9b-it
      - id: llama-3.1-8b
        providerModel: llama-3.1-8b-instant
    responseCommand:
      executable: curl
      args:
        - -s
        - https://api.groq.com/openai/v1/chat/completions
        - -H
        - "Authorization: Bearer $GROQ_API_KEY"
        - -H
        - "Content-Type: application/json"
        - -d
        - |
          {
            "model": "{{provider_model}}",
            "messages": [{"role": "user", "content": "{{prompt}}"}],
            "temperature": 0.7
          }
      input: prompt_stdin
      output: text_contract_final_line
      timeoutMs: 60000
    auth:
      statusCommand:
        executable: sh
        args:
          - -c
          - |
            if [ -z "$GROQ_API_KEY" ]; then
              echo '{"ok":false,"error":"GROQ_API_KEY not set"}'
              exit 1
            fi
            curl -s -o /dev/null -w "%{http_code}" \
              https://api.groq.com/openai/v1/models \
              -H "Authorization: Bearer $GROQ_API_KEY" | grep -q "200" && \
              echo '{"ok":true}' || echo '{"ok":false,"error":"Invalid API key"}'
        timeoutMs: 10000

  - id: deepseek-api
    type: cli
    description: DeepSeek API - excellent for coding tasks with free tier
    models:
      - id: deepseek-chat
        providerModel: deepseek-chat
        fallbackModels:
          - deepseek-coder
      - id: deepseek-coder
        providerModel: deepseek-coder
        fallbackModels:
          - deepseek-chat
      - id: deepseek-reasoner
        providerModel: deepseek-reasoner
    responseCommand:
      executable: curl
      args:
        - -s
        - https://api.deepseek.com/chat/completions
        - -H
        - "Authorization: Bearer $DEEPSEEK_API_KEY"
        - -H
        - "Content-Type: application/json"
        - -d
        - |
          {
            "model": "{{provider_model}}",
            "messages": [{"role": "user", "content": "{{prompt}}"}],
            "temperature": 0.7
          }
      input: prompt_stdin
      output: text_contract_final_line
      timeoutMs: 120000
    auth:
      statusCommand:
        executable: sh
        args:
          - -c
          - |
            if [ -z "$DEEPSEEK_API_KEY" ]; then
              echo '{"ok":false,"error":"DEEPSEEK_API_KEY not set"}'
              exit 1
            fi
            curl -s -o /dev/null -w "%{http_code}" \
              https://api.deepseek.com/models \
              -H "Authorization: Bearer $DEEPSEEK_API_KEY" | grep -q "200" && \
              echo '{"ok":true}' || echo '{"ok":false,"error":"Invalid API key"}'
        timeoutMs: 10000
