apiVersion: v1
kind: Namespace
metadata:
  name: n8n-openai-gateway
  labels:
    app.kubernetes.io/name: n8n-openai-cli-gateway
---
apiVersion: v1
kind: Secret
metadata:
  name: n8n-openai-cli-gateway-secrets
  namespace: n8n-openai-gateway
type: Opaque
stringData:
  n8nApiKey: "replace-with-long-random-n8n-key"
  adminApiKey: "replace-with-long-random-admin-key"
---
apiVersion: v1
kind: Secret
metadata:
  name: ghcr-secret
  namespace: n8n-openai-gateway
type: kubernetes.io/dockerconfigjson
stringData:
  .dockerconfigjson: |
    {
      "auths": {
        "ghcr.io": {
          "username": "replace-with-github-username",
          "password": "replace-with-github-token-read-packages"
        }
      }
    }
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: n8n-openai-cli-gateway
  namespace: n8n-openai-gateway
imagePullSecrets:
  - name: ghcr-secret
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: n8n-openai-cli-gateway-config
  namespace: n8n-openai-gateway
data:
  providers.yaml: |
    providers:
      - id: gemini-cli
        type: cli
        description: Gemini via OpenCode + Google OAuth plugin
        models:
          - id: gemini-2.5-pro
            providerModel: google/gemini-2.5-pro
          - id: gemini-2.5-flash
            providerModel: google/gemini-2.5-flash
        responseCommand:
          executable: opencode
          args:
            - run
            - --model
            - "{{provider_model}}"
            - --format
            - default
            - "{{prompt}}"
          input: prompt_stdin
          output: text
          timeoutMs: 240000
        auth:
          loginCommand:
            executable: opencode
            args:
              - auth
              - login
            timeoutMs: 900000
          statusCommand:
            executable: sh
            args:
              - -c
              - opencode auth list | grep -qi google
            timeoutMs: 30000
      - id: antigravity-cli
        type: cli
        description: Antigravity CLI adapter
        models:
          - id: antigravity-default
            providerModel: default
        responseCommand:
          executable: antigravity
          args:
            - chat
            - --model
            - "{{provider_model}}"
            - --json
          input: request_json_stdin
          output: json_contract
          timeoutMs: 240000
        auth:
          loginCommand:
            executable: antigravity
            args:
              - auth
              - login
              - --no-browser
            timeoutMs: 900000
          statusCommand:
            executable: antigravity
            args:
              - auth
              - status
              - --json
            timeoutMs: 30000
      - id: codex-cli
        type: cli
        description: OpenAI Codex CLI adapter
        models:
          - id: codex-latest
            providerModel: codex-latest
          - id: gpt-4.1
            providerModel: gpt-4.1
        responseCommand:
          executable: codex
          args:
            - chat
            - --model
            - "{{provider_model}}"
            - --json
          input: request_json_stdin
          output: json_contract
          timeoutMs: 240000
        auth:
          loginCommand:
            executable: codex
            args:
              - login
              - --no-browser
            timeoutMs: 900000
          statusCommand:
            executable: codex
            args:
              - whoami
              - --json
            timeoutMs: 30000
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: n8n-openai-cli-gateway-opencode-config
  namespace: n8n-openai-gateway
data:
  opencode.json: |
    {
      "$schema": "https://opencode.ai/config.json",
      "plugin": ["opencode-gemini-auth@latest"]
    }
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: n8n-openai-cli-gateway-home
  namespace: n8n-openai-gateway
spec:
  # Set this if your cluster does not have a default storage class.
  # storageClassName: replace-with-storageclass
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: n8n-openai-cli-gateway
  namespace: n8n-openai-gateway
spec:
  replicas: 1
  selector:
    matchLabels:
      app: n8n-openai-cli-gateway
  template:
    metadata:
      labels:
        app: n8n-openai-cli-gateway
    spec:
      serviceAccountName: n8n-openai-cli-gateway
      nodeSelector:
        kubernetes.io/arch: arm64
      securityContext:
        runAsNonRoot: true
        runAsUser: 10001
        runAsGroup: 10001
        fsGroup: 10001
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: gateway
          image: ghcr.io/philly1084/n8n-openai-cli-gateway:main
          imagePullPolicy: Always
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: false
            capabilities:
              drop: ["ALL"]
          ports:
            - containerPort: 8080
              name: http
          env:
            - name: PORT
              value: "8080"
            - name: HOST
              value: "0.0.0.0"
            - name: LOG_LEVEL
              value: "info"
            - name: MAX_JOB_LOG_LINES
              value: "500"
            - name: PROVIDERS_CONFIG_PATH
              value: /app/config/providers.yaml
            - name: HOME
              value: /var/lib/gateway-home
            - name: N8N_API_KEY
              valueFrom:
                secretKeyRef:
                  name: n8n-openai-cli-gateway-secrets
                  key: n8nApiKey
            - name: ADMIN_API_KEY
              valueFrom:
                secretKeyRef:
                  name: n8n-openai-cli-gateway-secrets
                  key: adminApiKey
          volumeMounts:
            - name: providers-config
              mountPath: /app/config/providers.yaml
              subPath: providers.yaml
            - name: provider-home
              mountPath: /var/lib/gateway-home
            - name: opencode-config
              mountPath: /var/lib/gateway-home/.config/opencode
          livenessProbe:
            httpGet:
              path: /healthz
              port: 8080
            initialDelaySeconds: 20
            periodSeconds: 15
          startupProbe:
            httpGet:
              path: /healthz
              port: 8080
            failureThreshold: 30
            periodSeconds: 5
          readinessProbe:
            httpGet:
              path: /healthz
              port: 8080
            initialDelaySeconds: 10
            periodSeconds: 10
          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              cpu: "1"
              memory: 1Gi
      volumes:
        - name: providers-config
          configMap:
            name: n8n-openai-cli-gateway-config
        - name: provider-home
          persistentVolumeClaim:
            claimName: n8n-openai-cli-gateway-home
        - name: opencode-config
          configMap:
            name: n8n-openai-cli-gateway-opencode-config
---
apiVersion: v1
kind: Service
metadata:
  name: n8n-openai-cli-gateway
  namespace: n8n-openai-gateway
  labels:
    app: n8n-openai-cli-gateway
spec:
  type: ClusterIP
  selector:
    app: n8n-openai-cli-gateway
  ports:
    - name: http
      port: 80
      targetPort: 8080
      protocol: TCP
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: n8n-openai-cli-gateway
  namespace: n8n-openai-gateway
  annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: "10m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - gateway.example.com
      secretName: n8n-openai-cli-gateway-tls
  rules:
    - host: gateway.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: n8n-openai-cli-gateway
                port:
                  number: 80
