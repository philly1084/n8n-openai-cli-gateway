apiVersion: v1
kind: Namespace
metadata:
  name: n8n-openai-gateway
  labels:
    app.kubernetes.io/name: n8n-openai-cli-gateway
---
apiVersion: v1
kind: Secret
metadata:
  name: n8n-openai-cli-gateway-secrets
  namespace: n8n-openai-gateway
type: Opaque
stringData:
  n8nApiKey: "replace-with-long-random-n8n-key"
  adminApiKey: "replace-with-long-random-admin-key"
---
apiVersion: v1
kind: Secret
metadata:
  name: ghcr-secret
  namespace: n8n-openai-gateway
type: kubernetes.io/dockerconfigjson
stringData:
  .dockerconfigjson: |
    {
      "auths": {
        "ghcr.io": {
          "username": "replace-with-github-username",
          "password": "replace-with-github-token-read-packages"
        }
      }
    }
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: n8n-openai-cli-gateway
  namespace: n8n-openai-gateway
imagePullSecrets:
  - name: ghcr-secret
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: n8n-openai-cli-gateway-config
  namespace: n8n-openai-gateway
data:
  providers.yaml: |
    providers:
      - id: gemini-cli
        type: cli
        description: Gemini CLI adapter
        models:
          - id: gemini-3-pro-preview
            providerModel: gemini-3-pro-preview
          - id: gemini-3-flash-preview
            providerModel: gemini-3-flash-preview
          - id: gemini-2.5-pro
            providerModel: gemini-2.5-pro
          - id: gemini-2.5-flash
            providerModel: gemini-2.5-flash
          - id: gemini-2.5-flash-lite
            providerModel: gemini-2.5-flash-lite
        responseCommand:
          executable: sh
          args:
            - -lc
            - |
              REQUEST_JSON="$(cat)"
              PROMPT="$(
                printf "%s" "$REQUEST_JSON" | node -e 'let d="";process.stdin.on("data",c=>d+=c).on("end",()=>{const req=JSON.parse(d);const msgs=Array.isArray(req.messages)?req.messages:[];const tools=Array.isArray(req.tools)?req.tools:[];const norm=v=>typeof v==="string"?v:JSON.stringify(v??"");const msgText=msgs.map(m=>`${String(m.role||"user").toUpperCase()}:\n${norm(m.content)}`).join("\n\n");const toolJson=JSON.stringify(tools,null,2);const instruction=["You are connected through an OpenAI-compatible gateway.","If you need to call a tool, respond ONLY with JSON:","{\"output_text\":\"\",\"tool_calls\":[{\"id\":\"call_1\",\"name\":\"tool_name\",\"arguments\":{\"arg\":\"value\"}}],\"finish_reason\":\"tool_calls\"}","If no tool is needed, respond ONLY with JSON:","{\"output_text\":\"<assistant reply>\",\"finish_reason\":\"stop\"}"].join("\n");process.stdout.write([msgText,"","AVAILABLE_TOOLS_JSON:",toolJson,"",instruction].join("\n"));});'
              )"
              RAW_OUTPUT="$(gemini --model "{{provider_model}}" --output-format text --prompt "$PROMPT")" || exit $?
              printf "%s" "$RAW_OUTPUT" | node -e 'let d="";process.stdin.on("data",c=>d+=c).on("end",()=>{const t=d.trim();if(!t){process.stdout.write(JSON.stringify({output_text:"",finish_reason:"stop"}));return;}try{const j=JSON.parse(t);if(j&&typeof j==="object"){process.stdout.write(JSON.stringify(j));return;}}catch{}const lines=t.split(/\r?\n/).reverse();for(const line of lines){const c=line.trim();if(!c)continue;try{const j=JSON.parse(c);if(j&&typeof j==="object"){process.stdout.write(JSON.stringify(j));return;}}catch{}}process.stdout.write(JSON.stringify({output_text:t,finish_reason:"stop"}));});'
          input: request_json_stdin
          output: json_contract
          timeoutMs: 240000
        auth:
          loginCommand:
            executable: sh
            args:
              - -c
              - |
                echo "Gemini CLI login is interactive in this version."
                echo "Run in a TTY shell: gemini"
                echo "Then run: /auth and choose Login with Google."
                exit 1
            timeoutMs: 10000
          statusCommand:
            executable: sh
            args:
              - -c
              - |
                test -f "$HOME/.gemini/oauth_creds.json" \
                  && echo '{"ok":true,"source":"oauth_creds.json"}' \
                  || (echo '{"ok":false,"error":"missing ~/.gemini/oauth_creds.json"}' && exit 1)
            timeoutMs: 30000
      - id: antigravity-cli
        type: cli
        description: Antigravity CLI adapter
        models:
          - id: antigravity-default
            providerModel: default
        responseCommand:
          executable: antigravity
          args:
            - chat
            - --model
            - "{{provider_model}}"
            - --json
          input: request_json_stdin
          output: json_contract
          timeoutMs: 240000
        auth:
          loginCommand:
            executable: antigravity
            args:
              - auth
              - login
              - --no-browser
            timeoutMs: 900000
          statusCommand:
            executable: antigravity
            args:
              - auth
              - status
              - --json
            timeoutMs: 30000
      - id: codex-cli
        type: cli
        description: OpenAI (Codex CLI) adapter
        models:
          - id: codex-latest
            providerModel: codex-latest
          - id: openai-codex-latest
            providerModel: codex-latest
          - id: gpt-4.1
            providerModel: gpt-4.1
          - id: openai-gpt-4.1
            providerModel: gpt-4.1
        responseCommand:
          executable: codex
          args:
            - chat
            - --model
            - "{{provider_model}}"
            - --json
          input: request_json_stdin
          output: json_contract
          timeoutMs: 240000
        auth:
          loginCommand:
            executable: codex
            args:
              - login
              - --no-browser
            timeoutMs: 900000
          statusCommand:
            executable: codex
            args:
              - whoami
              - --json
            timeoutMs: 30000
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: n8n-openai-cli-gateway-home
  namespace: n8n-openai-gateway
spec:
  # Set this if your cluster does not have a default storage class.
  # storageClassName: replace-with-storageclass
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 5Gi
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: n8n-openai-cli-gateway
  namespace: n8n-openai-gateway
spec:
  replicas: 1
  selector:
    matchLabels:
      app: n8n-openai-cli-gateway
  template:
    metadata:
      labels:
        app: n8n-openai-cli-gateway
    spec:
      serviceAccountName: n8n-openai-cli-gateway
      nodeSelector:
        kubernetes.io/arch: arm64
      securityContext:
        runAsNonRoot: true
        runAsUser: 10001
        runAsGroup: 10001
        fsGroup: 10001
        seccompProfile:
          type: RuntimeDefault
      containers:
        - name: gateway
          image: ghcr.io/philly1084/n8n-openai-cli-gateway:main
          imagePullPolicy: Always
          securityContext:
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: false
            capabilities:
              drop: ["ALL"]
          ports:
            - containerPort: 8080
              name: http
          env:
            - name: PORT
              value: "8080"
            - name: HOST
              value: "0.0.0.0"
            - name: LOG_LEVEL
              value: "info"
            - name: MAX_JOB_LOG_LINES
              value: "500"
            - name: PROVIDERS_CONFIG_PATH
              value: /app/config/providers.yaml
            - name: HOME
              value: /var/lib/gateway-home
            - name: N8N_API_KEY
              valueFrom:
                secretKeyRef:
                  name: n8n-openai-cli-gateway-secrets
                  key: n8nApiKey
            - name: ADMIN_API_KEY
              valueFrom:
                secretKeyRef:
                  name: n8n-openai-cli-gateway-secrets
                  key: adminApiKey
          volumeMounts:
            - name: providers-config
              mountPath: /app/config/providers.yaml
              subPath: providers.yaml
            - name: provider-home
              mountPath: /var/lib/gateway-home
          livenessProbe:
            httpGet:
              path: /healthz
              port: 8080
            initialDelaySeconds: 20
            periodSeconds: 15
          startupProbe:
            httpGet:
              path: /healthz
              port: 8080
            failureThreshold: 30
            periodSeconds: 5
          readinessProbe:
            httpGet:
              path: /healthz
              port: 8080
            initialDelaySeconds: 10
            periodSeconds: 10
          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              cpu: "1"
              memory: 1Gi
      volumes:
        - name: providers-config
          configMap:
            name: n8n-openai-cli-gateway-config
        - name: provider-home
          persistentVolumeClaim:
            claimName: n8n-openai-cli-gateway-home
---
apiVersion: v1
kind: Service
metadata:
  name: n8n-openai-cli-gateway
  namespace: n8n-openai-gateway
  labels:
    app: n8n-openai-cli-gateway
spec:
  type: ClusterIP
  selector:
    app: n8n-openai-cli-gateway
  ports:
    - name: http
      port: 80
      targetPort: 8080
      protocol: TCP
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: n8n-openai-cli-gateway
  namespace: n8n-openai-gateway
  annotations:
    nginx.ingress.kubernetes.io/proxy-body-size: "10m"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "300"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "300"
spec:
  ingressClassName: nginx
  tls:
    - hosts:
        - gateway.example.com
      secretName: n8n-openai-cli-gateway-tls
  rules:
    - host: gateway.example.com
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: n8n-openai-cli-gateway
                port:
                  number: 80
